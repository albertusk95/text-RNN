{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from helper import *\n",
    "from model import *\n",
    "import os\n",
    "\n",
    "script = 'linux'\n",
    "\n",
    "pickle_path = './model/' + script + '/' + script + '_preprocess.p'\n",
    "save_dir = './model/' + script + '/' + script\n",
    "\n",
    "pickle_path = os.path.join(pickle_path)\n",
    "save_dir = os.path.join(save_dir)\n",
    "\n",
    "print(\"Training Started...\\n\")\n",
    "int_text, vocab_to_int, int_to_vocab = load_preprocess(pickle_path)\n",
    "\n",
    "print(\"Data Loaded! \\n\")\n",
    "\n",
    "vocab_size = len(vocab_to_int.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Hyperparameters.\n",
    "num_epochs  = 1000\n",
    "batch_size  = 10\n",
    "rnn_size    = 512\n",
    "num_layers  = 2\n",
    "embed_dim   = 512\n",
    "seq_length  = 200\n",
    "lr          = 0.001\n",
    "keep_prob   = 0.5\n",
    "temperature = 1.0\n",
    "grad_clip   = 5\n",
    "decay_rate  = 0.97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Started...\n",
      "\n",
      "Data Loaded! \n",
      "\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "nn = text_rnn(batch_size, seq_length, rnn_size, num_layers, vocab_size, embed_dim, grad_clip)\n",
    "saver = tf.train.Saver(tf.global_variables(), max_to_keep=3,keep_checkpoint_every_n_hours=0.5)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    check = tf.train.latest_checkpoint('./model/'+ script +'/')\n",
    "    if check == None:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "    else:\n",
    "        saver.restore(sess, check)\n",
    "        print(\"MODEL RESTORED\", check)\n",
    "\n",
    "    for epoch in range(num_epochs+1):\n",
    "        state = sess.run(nn.initial_state)\n",
    "        lr = lr * (decay_rate ** epoch)\n",
    "        for (x, y) in next_batch(int_text, batch_size, seq_length):\n",
    "            feed = {\n",
    "                nn.inputs: x,\n",
    "                nn.targets: y,\n",
    "                nn.initial_state: state,\n",
    "                nn.learning_rate: lr,\n",
    "                nn.keep_prob: keep_prob,\n",
    "                nn.temp: temperature\n",
    "                }\n",
    "            train_loss, state, _ = sess.run([nn.cost, nn.final_state, nn.optimizer], feed_dict=feed)\n",
    "\n",
    "        print('Epoch %i  train_loss = %0.3f'%(epoch,train_loss))\n",
    "        if epoch%50 == 0 and epoch:\n",
    "            # Save Model\n",
    "            saver.save(sess, save_dir, global_step=epoch)\n",
    "            print('Model Saved...')\n",
    "    # Save Model\n",
    "    saver.save(sess, save_dir, global_step=epoch)\n",
    "    print('Model Trained and Saved')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
